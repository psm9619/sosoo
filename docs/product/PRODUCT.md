# VoiceUp 제품 가이드라인

이 문서는 VoiceUp 서비스의 핵심 제품 원칙과 AI 동작 가이드라인을 정의합니다.

---

## 1. 핵심 원칙: 정보 진실성 (Information Integrity)

### 목표
AI가 생성하는 모든 콘텐츠는 **사용자가 제공한 정보만을 기반**으로 해야 합니다.

### 이유
- 면접/발표 연습 서비스에서 가짜 정보는 **치명적인 결과**를 초래할 수 있음
- 사용자가 AI가 만든 가짜 경험/성과를 실제 면접에서 말하면 **신뢰도 상실** 및 **불합격**
- 서비스 전체의 **신뢰성 훼손**

### 절대 금지 사항
- 원본에 없는 학교, 전공, 직장명 추가
- 원본에 없는 경험, 성과, 프로젝트 생성
- 구체적인 수치, 기간, 역할 임의 추가
- "~한 경험이 있습니다", "~를 전공했습니다" 등 사실 창작

---

## 2. 발생 사례 및 수정 이력

### Case 001: AI 환각 (Hallucination) - 2026.02.01

**발생 상황**
- 사용자 원본: "안녕하세요 제 이름은 박수민입니다 뭐라고 말해야 될지 모르겠네요"
- AI 개선안: "안녕하세요, 제 이름은 박수민입니다. 저는 현재 대학교에서 **경영학을 전공**하고 있고, 지난 학기에 **팀 프로젝트에서 리더 역할**을 맡아 **좋은 성과를 거둔 경험**이 있습니다..."

**문제점**
- 원본에 전혀 없는 정보(경영학 전공, 팀 프로젝트 리더, 성과 경험)를 AI가 임의로 생성
- 사용자가 이를 실제 면접에서 사용하면 거짓말이 됨

**수정 내용**

1. **`IMPROVEMENT_SYSTEM_PROMPT` 강화** (`lib/ai/prompts.ts`)
```
## 절대 금지 사항 (가장 중요)
⚠️ 원본에 없는 정보를 절대 추가하지 마세요!
- 원본에 언급되지 않은 학교, 전공, 직장, 경험, 성과, 목표를 지어내지 마세요
- 구체적인 수치, 기간, 역할을 임의로 추가하지 마세요
- 이를 위반하면 사용자에게 심각한 피해를 줄 수 있습니다
```

2. **내용 부족 시 에러 반환** (`lib/ai/nodes/improvement.ts`)
- 5단어 미만 입력 시 즉시 에러 반환
- AI가 내용 부족 판단 시 `INSUFFICIENT_CONTENT` 에러 반환
- 프론트엔드에서 "답변이 너무 짧습니다" 메시지 표시

3. **프롬프트 빌더 강화** (`buildImprovementPrompt`)
- 매 요청 시작 시 경고 문구 삽입
- 지시사항에 "새로운 사실, 경험, 수치를 추가하지 마세요" 명시

**올바른 동작 예시**
- 원본: "안녕하세요 제 이름은 박수민입니다 뭐라고 말해야 될지 모르겠네요"
- 개선: "안녕하세요, 제 이름은 박수민입니다." (불필요한 부분만 제거)

---

## 3. AI 개선 허용 범위

### 허용되는 수정
| 항목 | 설명 | 예시 |
|------|------|------|
| 추임새 제거 | 어, 음, 그, 이제 등 | "어... 저는" → "저는" |
| 문장 구조 정리 | 흐름 개선 | 끊어진 문장 연결 |
| 반복 표현 정리 | 중복 제거 | "그래서 그래서" → "그래서" |
| 불명확한 표현 개선 | 의미 변경 없이 | "그거" → (문맥상 명확한 표현) |

### 금지되는 수정
| 항목 | 설명 | 예시 |
|------|------|------|
| 새로운 사실 추가 | 원본에 없는 정보 | 전공, 경력, 성과 추가 |
| 수치/기간 추가 | 구체적 숫자 | "3년 경력", "20% 성과" |
| 역할/직책 추가 | 직무 관련 | "팀 리더", "PM" |
| 목표/비전 추가 | 미래 계획 | "~하고 싶습니다" (원본에 없으면) |

---

## 4. 에러 처리 정책

### 내용 부족 시 처리
```
조건: 단어 수 < 5 OR AI가 내용 부족 판단
결과: INSUFFICIENT_CONTENT 에러
메시지: "답변 내용이 부족하여 개선안을 생성할 수 없습니다. 더 구체적으로 말씀해주세요."
UI: 다시 녹음 유도
```

### 에러 코드
| 코드 | 설명 | 사용자 메시지 |
|------|------|---------------|
| `INSUFFICIENT_CONTENT` | 내용 부족 | 답변이 너무 짧습니다 |
| `AUDIO_TOO_SHORT` | 녹음 시간 부족 | 최소 5초 이상 녹음해주세요 |
| `AUDIO_NO_SPEECH` | 음성 미감지 | 음성이 감지되지 않았습니다 |

---

## 5. 우선순위 랭킹 시스템 (Priority Ranking System)

### 개요
사용자의 상황(면접/발표/자유스피치)에 따라 피드백 우선순위를 동적으로 조정하는 시스템입니다.

### 핵심 개념
- **상황 분류**: 텍스트에서 키워드를 분석하여 상황 유형을 자동 분류
- **동적 가중치**: 상황별로 4가지 카테고리에 다른 가중치 적용
- **맞춤 피드백**: 가장 중요한 개선점을 우선적으로 제시

### 4가지 분석 카테고리

| 카테고리 | 설명 | 측정 항목 |
|----------|------|-----------|
| **전달력 (Delivery)** | 말하기 품질 | 말 속도(WPM), 필러워드 비율, 문장 완결성 |
| **구조력 (Structure)** | 논리적 흐름 | STAR 구조, 두괄식 표현, 연결어 사용 |
| **내용력 (Content)** | 구체적 정보 | 숫자/성과 언급, 사례 제시, 전문성 |
| **설득력 (Persuasion)** | 전달 영향력 | 자신감 표현, 겸양 표현, 강조 표현 |

### 상황별 가중치 매트릭스

| 상황 | 전달력 | 구조력 | 내용력 | 설득력 |
|------|--------|--------|--------|--------|
| 기술 면접 | 0.8 | 1.0 | **1.3** | 0.9 |
| 인성 면접 | 1.0 | **1.2** | 1.0 | 1.1 |
| 일반 면접 | 1.0 | 1.1 | 1.1 | 1.0 |
| 피치/발표 | 1.1 | 1.0 | 1.0 | **1.3** |
| 보고/브리핑 | 0.9 | **1.3** | 1.2 | 0.8 |
| 자유 스피치 | **1.3** | 0.8 | 0.9 | 1.1 |

> **가중치 해석**: 1.0 = 기본, 1.3 = 매우 중요, 0.8 = 상대적으로 덜 중요

### 상황 분류 키워드 예시

| 상황 유형 | 감지 키워드 |
|-----------|-------------|
| 기술 면접 | 기술, 개발, 구현, API, 서버, 알고리즘, Python, React |
| 인성 면접 | 팀, 협업, 리더, 갈등, 극복, 성장, 커뮤니케이션 |
| 피치/발표 | 투자, 비즈니스, 시장, 고객, 솔루션, 성장, 매출 |
| 보고/브리핑 | 보고, 결과, 분석, 데이터, 현황, KPI, 달성률 |

### 피드백 우선순위 결정 공식

```
피드백 우선순위 = (100 - 원본점수) × 가중치
```

낮은 점수 + 높은 가중치 = 높은 피드백 우선순위

### 사용 예시

**기술 면접 상황**
- 사용자가 "API 설계 경험"에 대해 답변
- 상황 자동 분류: `interview_technical`
- 내용력(1.3)이 가장 중요 → 구체적 숫자/성과 부족 시 최우선 피드백

**자유 스피치 상황**
- 사용자가 자유 주제로 연습
- 상황 자동 분류: `free_speech`
- 전달력(1.3)이 가장 중요 → 말 속도, 필러워드 개선 최우선

---

## 6. 컨텍스트 기반 맞춤 질문 생성

### 개요
사용자가 업로드한 이력서/발표자료를 AI가 분석하여 **실제 경험에 기반한 맞춤 면접 질문**을 생성합니다.

### Long-term Memory 구조

사용자 문서에서 추출하여 프로젝트에 저장되는 컨텍스트:

| 필드 | 설명 | 용도 |
|------|------|------|
| `contextSummary` | 문서 요약 (3-5문장) | 질문 생성 시 전체 맥락 |
| `contextKeywords` | 핵심 키워드 (기술, 역량) | 기술 면접 질문 도출 |
| `contextExperiences` | 주요 경험/프로젝트 | STAR 기반 역량 질문 |
| `contextStrengths` | 강점 목록 | 강점 기반 질문 |
| `potentialQuestionAreas` | 질문 가능 영역 | 질문 주제 선정 |

### 카테고리별 질문 수

| 카테고리 | 한글명 | 생성 | 선별 | 특성 |
|---------|--------|------|------|------|
| `basic` | 자기소개 | 2개 | **1개** | 간단한 배경 확인 |
| `motivation` | 지원동기 | 3개 | **2개** | 회사/직무 이해 |
| `competency` | 역량 | 6개 | **4개** | 핵심 성과, 팀워크 |
| `technical` | 기술 | 6개 | **4개** | 기술 지식, 프로젝트 |
| `situation` | 상황대처 | 3개 | **2개** | 갈등/실패 대응 |
| `culture_fit` | 컬쳐핏 | 2개 | **1개** | 가치관, 성장 목표 |
| **총합** | | **22개** | **14개** | |

### "더 많이 생성 → 베스트 선별" 전략

AI가 각 카테고리별로 필요 개수보다 더 많은 후보 질문을 생성한 뒤, 품질 기준에 따라 최종 질문을 선별합니다.

**생성/선별 비율:**
```
필요 개수  →  생성 개수  →  선별 개수
    1     →      2      →      1
    2     →      3      →      2
    3     →      5      →      3
    4     →      6      →      4
```

### 품질 기준 (Quality Criteria)

**좋은 질문 조건 (선별됨):**
| 기준 | 설명 |
|------|------|
| 맞춤성 | 지원자의 **구체적인 경험/프로젝트**를 언급 |
| 답변 용이성 | 지원자가 **실제로 답할 수 있는** 내용 |
| 차별화 | 일반적인 질문이 아닌, **이 지원자만을 위한** 질문 |
| 깊이 | 표면적 확인이 아닌 **사고 과정**을 물을 수 있는 질문 |
| 명확성 | 질문 의도가 명확하고 **한 가지 주제**에 집중 |

**나쁜 질문 조건 (탈락):**
- 너무 광범위하거나 모호한 질문
- 예/아니오로 답할 수 있는 닫힌 질문
- 컨텍스트와 무관한 일반적인 질문
- 여러 질문이 하나에 섞인 복합 질문

### 질문 생성 예시

**입력 (이력서 분석 결과):**
```
요약: 3년차 프론트엔드 개발자, React/TypeScript 전문
경험: 쇼핑몰 리뉴얼 (페이지 로딩 40% 개선, 매출 15% 증가)
강점: 성능 최적화, 비즈니스 임팩트 중심 사고
```

**출력 (맞춤 질문):**

| 일반 질문 (X) | VoiceUp 맞춤 질문 (O) |
|---------------|----------------------|
| "자기소개 해주세요" | "프론트엔드 개발자로서 본인의 강점과 함께 자기소개 해주세요" |
| "성능 최적화 경험 있나요?" | "쇼핑몰 리뉴얼에서 40% 성능 개선을 위해 어떤 최적화 기법을 적용하셨나요?" |
| "성과를 말씀해주세요" | "매출 15% 증가와 개발 작업의 인과관계를 어떻게 검증하셨나요?" |

---

## 7. 관련 파일

| 파일 | 역할 |
|------|------|
| `frontend/src/lib/ai/prompts.ts` | AI 시스템 프롬프트 정의 |
| `frontend/src/lib/ai/nodes/improvement.ts` | 개선안 생성 로직 |
| `frontend/src/lib/ai/nodes/analysis.ts` | 분석 로직 |
| `frontend/src/lib/ai/nodes/context.ts` | 컨텍스트 분석 (Long-term Memory) |
| `frontend/src/lib/ai/nodes/questions.ts` | 맞춤 질문 생성 + 품질 선별 |
| `frontend/src/lib/ai/tools/category-analyzer.ts` | 4가지 카테고리 분석 도구 |
| `frontend/src/lib/ai/tools/priority-tools.ts` | 우선순위 랭킹 시스템 |
| `frontend/src/lib/ai/state.ts` | LangGraph 상태 타입 정의 |
| `frontend/src/app/api/context/analyze/route.ts` | 컨텍스트 분석 API |
| `frontend/src/app/api/questions/generate/route.ts` | 질문 생성 API |

---

## 8. 오디오 파일 업로드 정책

### 지원 범위

| 연습 유형 | 오디오 파일 업로드 | 실시간 녹음 | 사유 |
|----------|-------------------|-------------|------|
| **빠른 연습 (면접)** | ✅ 지원 | ✅ 지원 | 사전 정의된 기본 질문 |
| **빠른 연습 (자유스피치)** | ✅ 지원 | ✅ 지원 | 질문 없음, 자유 주제 |
| **면접 프로젝트** | ❌ 미지원 | ✅ 지원 | 맞춤 질문 (예측 불가) |
| **발표 프로젝트** | ❌ 미지원 | ✅ 지원 | 맞춤 질문 (예측 불가) |

### 의도적 미지원 사유

**면접/발표 프로젝트에서 오디오 파일 업로드를 지원하지 않는 이유:**

1. **질문 커스텀 생성**: 사용자가 업로드한 이력서/발표자료를 AI가 분석하여 맞춤 질문을 생성
2. **예측 불가능한 질문**: 생성된 질문은 프로젝트 생성 시점에 결정되므로, 사전에 녹음된 오디오와 매칭 불가
3. **연습 효과 보장**: 실제 면접/발표처럼 질문을 보고 즉석에서 답변하는 연습이 더 효과적

### 파일 업로드 스펙 (빠른 연습)

| 항목 | 값 |
|------|-----|
| 지원 포맷 | webm, mp3, wav, m4a |
| 최대 크기 | 25MB |
| UI | 드래그앤드롭 + 클릭 업로드 |

---

## 9. Voice Cloning 동의 시스템

### 개요

Voice Cloning 기능은 사용자의 명시적 동의를 필요로 합니다. 동의 획득 방식은 **"읽기 동의" (Read-to-Consent)** 패턴을 사용합니다.

### 동의 획득 메커니즘

#### 단계별 플로우

```
1. 정책 안내 화면 (VoiceClonePolicy.tsx)
   - 개인정보 보호, AI 학습 금지, 서비스 내 사용, 삭제 권한 설명
   - 체크박스: "위 음성 데이터 보호 정책을 읽었으며... 동의합니다"
   ↓
2. 샘플 녹음 화면 (VoiceCloneRecorder.tsx)
   - 사용자가 동의 내용이 포함된 스크립트를 직접 읽어 녹음
   - 녹음 완료 시 동의 데이터 생성
   ↓
3. Supabase 저장 (API: /api/voice-clone)
   - voice_clones 테이블: 음성 샘플 URL, 상태
   - voice_clone_consents 테이블: 법적 증거용 동의 기록
   - users 테이블: voice_clone_consent = true
```

#### 동의 스크립트에 포함된 내용 (CONSENT_SAMPLE_TEXT)

사용자가 음성으로 직접 읽는 텍스트에 다음 내용이 포함되어 있습니다:

> *"저는 이 음성 샘플이 오직 저 자신의 발화 연습을 위해서만 사용될 것임을 이해합니다. 제 목소리는 다른 사람을 사칭하거나 부적절한 콘텐츠를 만드는 데 절대 사용되지 않을 것입니다."*

이 방식의 장점:
- **행동 기반 동의**: 단순 클릭이 아닌, 내용을 소리 내어 읽음으로써 인지 확인
- **법적 증거**: 녹음된 음성 자체가 동의의 증거가 됨
- **자연스러운 샘플 확보**: 30초-2분 분량의 자연스러운 음성 샘플 획득

### 저장되는 동의 정보

#### voice_clone_consents 테이블

| 필드 | 설명 | 예시 |
|------|------|------|
| `consent_version` | 정책 버전 | "v1.0" |
| `consent_text` | 사용자가 읽은 전체 텍스트 | (샘플 스크립트) |
| `consent_checkbox_text` | 체크박스 문구 | "위 내용을 읽었으며..." |
| `ip_address` | 요청 IP | "123.456.789.0" |
| `user_agent` | 브라우저 정보 | "Mozilla/5.0..." |
| `sample_duration_seconds` | 녹음 시간 | 45 |
| `created_at` | 동의 시각 | "2026-02-01T10:30:00Z" |

### 정책 버전 관리

```typescript
// lib/constants/voice-clone-consent.ts
export const CONSENT_VERSION = 'v1.0';
```

정책 변경 시:
1. `CONSENT_VERSION` 증가 (v1.0 → v1.1)
2. `CONSENT_SAMPLE_TEXT` 업데이트
3. 기존 동의 기록은 유지, 새 버전으로 재동의 요청 가능

### 삭제 권한 보장

- 마이페이지 설정에서 음성 클론 삭제 가능
- 삭제 시 처리:
  - ElevenLabs API에서 클론 삭제
  - Supabase Storage에서 샘플 파일 삭제
  - voice_clones 테이블에서 레코드 삭제
  - (동의 기록은 법적 증거로 보존)

### 관련 파일

| 파일 | 역할 |
|------|------|
| `src/lib/constants/voice-clone-consent.ts` | 동의 텍스트, 버전, 녹음 시간 상수 |
| `src/components/voice-clone/VoiceClonePolicy.tsx` | 정책 안내 + 체크박스 UI |
| `src/components/voice-clone/VoiceCloneRecorder.tsx` | 샘플 녹음 + 동의 데이터 생성 |
| `src/app/api/voice-clone/route.ts` | 클론 생성/삭제 + 동의 기록 저장 |

---

## 10. Voice Cloning TTS 자동 적용

### 개요

사용자가 Voice Clone을 등록하면, 이후 모든 분석에서 개선된 스피치가 **자동으로 클론 음성**으로 생성됩니다.

### 동작 플로우

```
[녹음 페이지]
    ↓
useVoiceClone: voiceClone.status === 'ready'  (자동 감지)
    ↓
[Analyze API] /api/analyze
    ↓
DB에서 voice_clones.elevenlabs_voice_id 조회
    ↓
[TTS 노드]
    ↓
voiceType === 'cloned' → 클론 음성 사용
```

### 코드 위치

| 위치 | 역할 |
|------|------|
| `studio/quick/page.tsx:132` | `useVoiceClone: voiceClone.status === 'ready'` |
| `studio/[projectId]/q/[questionId]/page.tsx:158` | 동일 |
| `app/api/analyze/route.ts:129-164` | DB에서 클론 ID 조회 |
| `lib/ai/nodes/tts.ts:39-45` | 클론 음성 ID로 TTS 호출 |

### 폴백 처리

클론 음성 TTS 실패 시 자동으로 기본 음성으로 재시도:

```typescript
// tts.ts:132-148
if (state.voiceType === 'cloned' && state.voiceCloneId) {
  try {
    const audioData = await textToSpeech(script, 'default_male');
    // 기본 음성으로 성공
  } catch {
    // 재시도도 실패
  }
}
```

---

## 11. Voice Cloning 관리 UI

### 마이페이지 설정 탭

| 기능 | 핸들러 | 설명 |
|------|--------|------|
| 삭제 | `handleDeleteVoiceClone` | ElevenLabs + Supabase에서 클론 삭제 |
| 재녹음 | `handleStartRecording` | 기존 클론 삭제 후 새 샘플 녹음 |

### UI 컴포넌트

**VoiceCloneStatus** (`components/voice-clone/VoiceCloneStatus.tsx`):

| 상태 | UI | 액션 |
|------|-----|------|
| `processing` | 스피너 + "1-2분 소요" | 백그라운드 진행 버튼 |
| `ready` | 체크마크 + "사용 가능" 배지 | 삭제 버튼 |
| `failed` | X 아이콘 + 에러 메시지 | 재시도 버튼 |

### 삭제 시 처리

```typescript
// DELETE /api/voice-clone
1. ElevenLabs API에서 음성 삭제
2. Supabase Storage에서 샘플 파일 삭제
3. voice_clones 테이블에서 레코드 삭제
4. (동의 기록은 법적 증거로 보존)
```

---

## 12. 콘텐츠 모더레이션 시스템

### 현재 구현 상태

**패턴 기반(Regex) 로컬 탐지 시스템**

AI 모델을 사용하지 않고, 정규식 패턴 매칭으로 즉시 탐지합니다.

### 탐지 유형

| 유형 | 한글명 | 심각도 | 처리 |
|------|--------|--------|------|
| `profanity` | 비속어 | medium | 마스킹 (`***`) |
| `discrimination` | 차별적 표현 | high | 마스킹 (`[부적절한 표현]`) |
| `threat` | 위협 | high | **차단** |
| `hate_speech` | 혐오 발언 | high | **차단** |
| `violence` | 폭력적 표현 | high | **차단** |
| `sensitive_personal` | 민감 개인정보 | low~high | 마스킹 |

### 민감 정보 마스킹

| 유형 | 예시 | 마스킹 결과 |
|------|------|------------|
| 전화번호 | `010-1234-5678` | `***-****-****` |
| 주민등록번호 | `900101-1234567` | `******-*******` |
| 이메일 | `user@example.com` | `use***@example.com` |
| 신용카드 | `1234-5678-9012-3456` | `****-****-****-****` |

### 처리 플로우

```
Audio → STT → Transcript
              ↓
        moderateContent()  ← 분석 전 필터링
              ↓
        [위협/혐오 감지 시]
              ↓
        에러 반환: "부적절한 콘텐츠가 감지되었습니다"
              ↓
        [통과 시]
              ↓
        maskedText로 AI 분석 진행
              ↓
        결과에 moderation 정보 첨부
```

### 차단 조건

```typescript
// moderation.ts:217-226
function isContentProcessable(result: ModerationResult): boolean {
  const hasBlockingContent = result.flags.some(
    (f) =>
      f.type === 'threat' ||
      (f.type === 'hate_speech' && f.severity === 'high') ||
      (f.type === 'violence' && f.severity === 'high')
  );
  return !hasBlockingContent;
}
```

### 사용자 경고 메시지

| 조건 | 메시지 |
|------|--------|
| 고위험 부적절 표현 | "부적절한 표현이 감지되어 일부 내용이 수정되었습니다. 면접/발표에서는 전문적인 언어 사용을 권장합니다." |
| 민감 정보 감지 | "개인정보 보호를 위해 민감한 정보가 자동으로 마스킹되었습니다." |

### 관련 파일

| 파일 | 역할 |
|------|------|
| `lib/ai/nodes/moderation.ts` | 모더레이션 로직 |
| `lib/ai/nodes/analysis.ts:54-62` | 분석 전 모더레이션 호출 |
| `lib/ai/nodes/analysis.ts:154-158` | 결과에 모더레이션 정보 첨부 |

### 현재 한계

1. **정규식 기반**: 패턴 우회 가능 (예: 특수문자 삽입)
2. **한국어 특화**: 영어/다국어 지원 제한적
3. **문맥 미고려**: 단순 패턴 매칭으로 오탐 가능성

### 향후 발전 방향

#### Phase 1: OpenAI Moderation API 통합

```typescript
// 예상 구현
import OpenAI from 'openai';

async function moderateWithOpenAI(text: string): Promise<ModerationResult> {
  const openai = new OpenAI();
  const response = await openai.moderations.create({ input: text });

  // 카테고리별 플래그 변환
  // hate, hate/threatening, self-harm, sexual, violence 등
}
```

**장점:**
- 문맥 기반 탐지 (더 정확)
- 다국어 지원
- 지속적 모델 업데이트

**고려사항:**
- 추가 API 비용 발생
- 지연 시간 증가 (네트워크 호출)

#### Phase 2: 하이브리드 접근

```
1단계: 로컬 패턴 매칭 (빠른 필터링)
    ↓
명확한 위반 → 즉시 차단
    ↓
2단계: OpenAI Moderation (애매한 케이스)
    ↓
정밀 분석 후 판정
```

#### Phase 3: 커스텀 분류기 학습

- 면접/발표 도메인 특화 모더레이션
- 사용자 피드백 기반 오탐 감소
- 한국어 특화 모델

---

## 13. 카테고리별 상세 피드백 시스템 (Category-based Feedback)

### 개요

기존의 **총점 기반 평가**를 **카테고리별 상세 피드백**으로 전환합니다.

- **적용 대상**: 면접 프로젝트 (기본 템플릿 + 컨텍스트 기반), 발표 프로젝트
- **미적용**: 자유 스피치 (기존 우선순위 랭킹 시스템 유지)

### 목표

1. 사용자가 **구체적으로 무엇을 고쳐야 하는지** 명확히 인지
2. 단순 점수가 아닌 **실행 가능한 피드백** 제공
3. **한 눈에 강점/약점 파악** 가능한 UI

### 피드백 구조

#### 3단 구조

```
┌──────────────────────────────────────────────────────┐
│ 1️⃣ 한 줄 평가 (Summary)                              │
│ "구조는 탄탄하지만, 필러워드를 줄이면 더 좋아요"      │
└──────────────────────────────────────────────────────┘
                          ↓
┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐
│🎙️전달력 │ │🧱구조력 │ │📝내용력 │ │🎯상황적합│
│  보통   │ │  좋음   │ │  좋음   │ │  보통   │
│⚠️필러워드│ │✓STAR완벽│ │✓수치구체│ │⚠️키워드│
└─────────┘ └─────────┘ └─────────┘ └─────────┘
                          ↓
┌──────────────────────────────────────────────────────┐
│ 3️⃣ 상세 피드백 (Expandable)                          │
│ 🎙️ 전달력                                            │
│ ├── 속도: ✅ Good - 140 WPM, 권장 범위 내            │
│ ├── 필러워드: ⚠️ 개선 필요                           │
│ │   └── "음" 5회, "아니 그러니까" 3회 감지           │
│ └── 명확성: ✅ Good - 문장 완결성 높음               │
└──────────────────────────────────────────────────────┘
```

### 메인 카테고리 (4개)

| 카테고리 | 설명 | 측정 항목 |
|----------|------|-----------|
| **전달력 (Delivery)** | 어떻게 말하는가 | 속도(WPM), 필러워드, 명확성 |
| **구조력 (Structure)** | 논리적 흐름 | STAR 구조, 도입-본론-결론, 논리적 연결 |
| **내용력 (Content)** | 무엇을 말하는가 | 구체성(숫자/성과), 관련성, 차별화 포인트 |
| **상황 적합성 (Context Fit)** | 맥락에 맞는가 | 질문 이해도, 핵심 키워드, 톤/태도 |

### 서브 카테고리 상세

#### 전달력 (Delivery)
| 서브 카테고리 | 데이터 소스 | 평가 기준 |
|---------------|-------------|-----------|
| 속도 | `pace-analysis` | 120-170 WPM = Good |
| 필러워드 | `filler-analysis` | ≤2% = Good, >6% = Bad |
| 명확성 | Claude 분석 | 문장 완결성, 발음 명확성 |

#### 구조력 (Structure)
| 서브 카테고리 | 데이터 소스 | 평가 기준 |
|---------------|-------------|-----------|
| STAR 구조 | `structure-analysis` | 4요소 존재 여부 |
| 도입-본론-결론 | Claude 분석 | 논리적 흐름 |
| 논리적 연결 | Claude 분석 | 연결어 사용 |

#### 내용력 (Content)
| 서브 카테고리 | 데이터 소스 | 평가 기준 |
|---------------|-------------|-----------|
| 구체성 | `structure-analysis.hasNumbers` + Claude | 숫자/성과 언급 |
| 관련성 | Claude 분석 | 질문과의 연관성 |
| 차별화 | Claude 분석 | 독창적 포인트 |

#### 상황 적합성 (Context Fit)
| 서브 카테고리 | 데이터 소스 | 평가 기준 |
|---------------|-------------|-----------|
| 질문 이해도 | Claude 분석 | 질문 의도 파악 |
| 핵심 키워드 | Long-term Context | JD/이력서 키워드 포함 |
| 톤/태도 | Claude 분석 | 면접/발표 상황 적합성 |

### 타입 정의

```typescript
// 새로운 분석 결과 타입
interface CategoryFeedback {
  // 한 줄 평가
  summary: string;

  // 메인 카테고리별 평가
  categories: {
    delivery: CategoryEvaluation;
    structure: CategoryEvaluation;
    content: CategoryEvaluation;
    contextFit: CategoryEvaluation;
  };
}

interface CategoryEvaluation {
  level: 'excellent' | 'good' | 'average' | 'needs_improvement';
  label: string;  // 한글 레이블 (예: "좋음", "보통")
  highlight: string;  // 카드에 표시할 핵심 포인트
  subcategories: SubcategoryEvaluation[];
}

interface SubcategoryEvaluation {
  name: string;           // 예: "속도", "필러워드"
  status: 'good' | 'warning' | 'bad';
  feedback: string;       // 예: "140 WPM, 권장 범위 내"
  details?: string[];     // 예: ["음 5회", "아니 그러니까 3회"]
}
```

### 프롬프트 변경

기존 프롬프트의 JSON 출력 형식을 새 구조로 변경:

```
## 출력 형식
반드시 아래 JSON 형식으로만 응답하세요:
{
  "summary": "전체 평가를 1문장으로 요약 (격려 + 핵심 개선점)",
  "categories": {
    "delivery": {
      "level": "excellent|good|average|needs_improvement",
      "highlight": "카드에 표시할 핵심 (예: '✓ 속도 적절' 또는 '⚠️ 필러워드')",
      "subcategories": [
        {
          "name": "속도",
          "status": "good|warning|bad",
          "feedback": "구체적 피드백"
        }
      ]
    },
    ...
  }
}
```

### UI 컴포넌트

| 컴포넌트 | 역할 | 위치 |
|----------|------|------|
| `FeedbackSummary` | 한 줄 평가 Hero 섹션 | 결과 페이지 상단 |
| `CategoryCards` | 4개 카테고리 요약 카드 | 한 줄 평가 아래 |
| `CategoryDetail` | 펼침 가능한 상세 피드백 | 카드 클릭 시 |

### 기존 데이터와의 호환

| 기존 필드 | 새 위치 | 비고 |
|-----------|---------|------|
| `scores` | 제거 | 카테고리별 level로 대체 |
| `metrics` | 유지 | WPM, 필러워드 수 등 원시 데이터 |
| `suggestions` | `summary` + subcategories | 통합 |
| `structureAnalysis` | `categories.structure` | 통합 |

### 관련 파일

| 파일 | 변경 내용 |
|------|-----------|
| `types/api.ts` | `CategoryFeedback` 타입 추가 |
| `lib/ai/prompts.ts` | `ANALYSIS_SYSTEM_PROMPT` 수정 |
| `lib/ai/nodes/analysis.ts` | 응답 파싱 로직 수정 |
| `components/feedback/*` | 새 UI 컴포넌트 (신규) |

---

## 변경 이력

| 날짜 | 내용 | 담당 |
|------|------|------|
| 2026-02-01 | 정보 진실성 원칙 수립, 프롬프트 강화 | AI Assistant |
| 2026-02-01 | 우선순위 랭킹 시스템 추가 (4가지 카테고리 분석) | AI Assistant |
| 2026-02-01 | 컨텍스트 기반 맞춤 질문 생성 시스템 추가 | AI Assistant |
| 2026-02-01 | "더 많이 생성 → 베스트 선별" 품질 전략 도입 | AI Assistant |
| 2026-02-01 | 오디오 파일 업로드 정책 추가 (프로젝트 의도적 미지원) | AI Assistant |
| 2026-02-01 | Voice Cloning 동의 시스템 문서화 (Read-to-Consent 패턴) | AI Assistant |
| 2026-02-01 | Voice Cloning TTS 자동 적용 및 관리 UI 문서화 | AI Assistant |
| 2026-02-01 | 콘텐츠 모더레이션 시스템 현황 및 발전 방향 문서화 | AI Assistant |
| 2026-02-01 | 카테고리별 상세 피드백 시스템 설계 (총점 → 카테고리 피드백) | Party Mode |
